## Introduction

A hidden Markov Model (HMM) is a statistical Markov model in which the system being modelled is assumed to be a Markov process with unobserved (hidden) states. The state is not directly visible, but the output dependant on the state, is visible. Each state has a probability distribution over the possible output tokens. Therefore, the sequence of tokens generated by an HMM gives some information about the sequence of states. The parameters of the model are known, it’s only the state sequence that is hidden. Hidden variables are usually referred as latent variables.
An HMM is a special case of a dynamic Bayesian network, a Bayesian network which relates variables to each other over adjacent time steps. It is often called Two-Timeslice BN because at any point in time T, the value of a variable can be calculated from the internal regressors and the immediate prior value at time T-1. At time 0, the Bayesian network is defined only by its values.
An HMM is completely represented given a transition matrix A, an observation matrix B and the initial state probabilities π.
The triplet λ = < A, B, π > fully define an HMM, where A is a distribution governing the probability of transition from any state value qi to another state value qj, B is a distribution governing the probability of observing symbol vk in every state value qi and π is a distribution specifying for every state value qi the probability of being in the initial state.

## Code example and more

Check the pdf file included [Learning graphical models](https://github.com/akyrey/HiddenMarkovModel_Solver/blob/master/Learning%20graphical%20models.pdf) for a description of the implementation, links and additional informations.

## Motivation

The project has been developed for university purpouse.

## License

HiddenMarkovModel_Solver is released under the [MIT license](https://github.com/akyrey/HiddenMarkovModel_Solver/raw/master/LICENSE).